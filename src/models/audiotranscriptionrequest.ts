/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v4-mini";
import { remap as remap$ } from "../lib/primitives.js";
import { blobLikeSchema } from "../types/blobs.js";
import { ClosedEnum } from "../types/enums.js";

export type FileT = {
  fileName: string;
  content: ReadableStream<Uint8Array> | Blob | ArrayBuffer | Uint8Array;
};

/**
 * Output format. Model support varies:
 *
 * @remarks
 * - whisper-1: Supports all formats (json, text, srt, verbose_json, vtt)
 * - gpt-4o-transcribe, gpt-4o-mini-transcribe: Only json and text
 */
export const AudioTranscriptionRequestResponseFormat = {
  Json: "json",
  Text: "text",
  Srt: "srt",
  VerboseJson: "verbose_json",
  Vtt: "vtt",
} as const;
/**
 * Output format. Model support varies:
 *
 * @remarks
 * - whisper-1: Supports all formats (json, text, srt, verbose_json, vtt)
 * - gpt-4o-transcribe, gpt-4o-mini-transcribe: Only json and text
 */
export type AudioTranscriptionRequestResponseFormat = ClosedEnum<
  typeof AudioTranscriptionRequestResponseFormat
>;

export const TimestampGranularities = {
  Word: "word",
  Segment: "segment",
} as const;
export type TimestampGranularities = ClosedEnum<typeof TimestampGranularities>;

export type AudioTranscriptionRequest = {
  /**
   * Audio file to transcribe
   */
  file: FileT | Blob;
  /**
   * Model name
   */
  model: string;
  /**
   * Audio language (ISO-639-1 format)
   */
  language?: string | undefined;
  /**
   * Optional text prompt
   */
  prompt?: string | undefined;
  /**
   * Output format. Model support varies:
   *
   * @remarks
   * - whisper-1: Supports all formats (json, text, srt, verbose_json, vtt)
   * - gpt-4o-transcribe, gpt-4o-mini-transcribe: Only json and text
   */
  responseFormat?: AudioTranscriptionRequestResponseFormat | undefined;
  temperature?: number | undefined;
  /**
   * Timestamp granularity levels to include. Options: word, segment.
   *
   * @remarks
   * **Important:** Only works when response_format is set to verbose_json.
   * Note: segment timestamps have no additional latency, but word timestamps add latency.
   */
  timestampGranularities?: Array<TimestampGranularities> | undefined;
};

/** @internal */
export type FileT$Outbound = {
  fileName: string;
  content: ReadableStream<Uint8Array> | Blob | ArrayBuffer | Uint8Array;
};

/** @internal */
export const FileT$outboundSchema: z.ZodMiniType<FileT$Outbound, FileT> = z
  .object({
    fileName: z.string(),
    content: z.union([
      z.custom<ReadableStream<Uint8Array>>(x => x instanceof ReadableStream),
      z.custom<Blob>(x => x instanceof Blob),
      z.custom<ArrayBuffer>(x => x instanceof ArrayBuffer),
      z.custom<Uint8Array>(x => x instanceof Uint8Array),
    ]),
  });

export function fileToJSON(fileT: FileT): string {
  return JSON.stringify(FileT$outboundSchema.parse(fileT));
}

/** @internal */
export const AudioTranscriptionRequestResponseFormat$outboundSchema:
  z.ZodMiniEnum<typeof AudioTranscriptionRequestResponseFormat> = z.enum(
    AudioTranscriptionRequestResponseFormat,
  );

/** @internal */
export const TimestampGranularities$outboundSchema: z.ZodMiniEnum<
  typeof TimestampGranularities
> = z.enum(TimestampGranularities);

/** @internal */
export type AudioTranscriptionRequest$Outbound = {
  file: FileT$Outbound | Blob;
  model: string;
  language?: string | undefined;
  prompt?: string | undefined;
  response_format: string;
  temperature: number;
  timestamp_granularities?: Array<string> | undefined;
};

/** @internal */
export const AudioTranscriptionRequest$outboundSchema: z.ZodMiniType<
  AudioTranscriptionRequest$Outbound,
  AudioTranscriptionRequest
> = z.pipe(
  z.object({
    file: z.union([z.lazy(() => FileT$outboundSchema), blobLikeSchema]),
    model: z.string(),
    language: z.optional(z.string()),
    prompt: z.optional(z.string()),
    responseFormat: z._default(
      AudioTranscriptionRequestResponseFormat$outboundSchema,
      "json",
    ),
    temperature: z._default(z.number(), 0),
    timestampGranularities: z.optional(
      z.array(TimestampGranularities$outboundSchema),
    ),
  }),
  z.transform((v) => {
    return remap$(v, {
      responseFormat: "response_format",
      timestampGranularities: "timestamp_granularities",
    });
  }),
);

export function audioTranscriptionRequestToJSON(
  audioTranscriptionRequest: AudioTranscriptionRequest,
): string {
  return JSON.stringify(
    AudioTranscriptionRequest$outboundSchema.parse(audioTranscriptionRequest),
  );
}
