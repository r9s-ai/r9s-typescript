/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v4-mini";
import { remap as remap$ } from "../lib/primitives.js";
import { ClosedEnum } from "../types/enums.js";
import { smartUnion } from "../types/smartUnion.js";
import {
  Message,
  Message$Outbound,
  Message$outboundSchema,
} from "./message.js";
import {
  ResponseTool,
  ResponseTool$Outbound,
  ResponseTool$outboundSchema,
} from "./responsetool.js";
import {
  ToolChoice,
  ToolChoice$Outbound,
  ToolChoice$outboundSchema,
} from "./toolchoice.js";

/**
 * Input content, required parameter. Can be:
 *
 * @remarks
 * - String: Single text input
 * - Message array: Structured conversation history
 *
 * **Important limitations:**
 * - Messages only support basic fields (role, content, name)
 * - Does not support tool_calls, tool_call_id and other tool-related fields
 * - content field is required and cannot be null
 * - To use tools, define them in the top-level tools parameter; model will call them on first response
 *
 * Note: Responses API has deprecated messages parameter, now uses input parameter uniformly
 */
export type Input = string | Array<Message>;

export const ResponseRequestModalities = {
  Text: "text",
  Audio: "audio",
} as const;
export type ResponseRequestModalities = ClosedEnum<
  typeof ResponseRequestModalities
>;

export const ResponseRequest1 = {
  None: "none",
  Auto: "auto",
  Required: "required",
} as const;
export type ResponseRequest1 = ClosedEnum<typeof ResponseRequest1>;

/**
 * Tool selection strategy
 */
export type ResponseRequestToolChoice = ToolChoice | ResponseRequest1;

/**
 * The type of response format
 */
export const ResponseRequestType = {
  Text: "text",
  JsonObject: "json_object",
  JsonSchema: "json_schema",
} as const;
/**
 * The type of response format
 */
export type ResponseRequestType = ClosedEnum<typeof ResponseRequestType>;

/**
 * An object specifying the format that the model must output. Setting to { "type": "json_schema", "name": "...", "schema": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema.
 *
 * @remarks
 * Setting to { "type": "json_object" } enables JSON mode, which ensures the model generates valid JSON.
 */
export type ResponseRequestFormat = {
  /**
   * The type of response format
   */
  type?: ResponseRequestType | undefined;
  /**
   * Name for the schema (required when type is json_schema)
   */
  name?: string | undefined;
  /**
   * JSON schema definition for structured outputs
   */
  schema?: { [k: string]: any } | undefined;
  /**
   * Whether to enforce strict schema matching
   */
  strict?: boolean | undefined;
};

/**
 * Verbosity level for the text output
 */
export const Verbosity = {
  Low: "low",
  Medium: "medium",
  High: "high",
} as const;
/**
 * Verbosity level for the text output
 */
export type Verbosity = ClosedEnum<typeof Verbosity>;

/**
 * Text output configuration
 */
export type Text = {
  /**
   * An object specifying the format that the model must output. Setting to { "type": "json_schema", "name": "...", "schema": {...} } enables Structured Outputs which ensures the model will match your supplied JSON schema.
   *
   * @remarks
   * Setting to { "type": "json_object" } enables JSON mode, which ensures the model generates valid JSON.
   */
  format?: ResponseRequestFormat | undefined;
  /**
   * Verbosity level for the text output
   */
  verbosity?: Verbosity | undefined;
};

/**
 * The effort level for reasoning (none/minimal=fast, low/medium=balanced, high/xhigh=thorough)
 */
export const Effort = {
  None: "none",
  Minimal: "minimal",
  Low: "low",
  Medium: "medium",
  High: "high",
  Xhigh: "xhigh",
} as const;
/**
 * The effort level for reasoning (none/minimal=fast, low/medium=balanced, high/xhigh=thorough)
 */
export type Effort = ClosedEnum<typeof Effort>;

/**
 * Configuration for reasoning models (e.g., o1, o3, gpt-5). Controls how the model uses reasoning tokens to "think" through the problem.
 */
export type Reasoning = {
  /**
   * The effort level for reasoning (none/minimal=fast, low/medium=balanced, high/xhigh=thorough)
   */
  effort?: Effort | undefined;
  /**
   * Summary of reasoning approach
   */
  summary?: string | undefined;
};

/**
 * The truncation strategy to use for the model response.
 *
 * @remarks
 * - auto: If input exceeds context window, truncate by dropping items from beginning
 * - disabled: Request fails with 400 error if input exceeds context window (default)
 */
export const Truncation = {
  Auto: "auto",
  Disabled: "disabled",
} as const;
/**
 * The truncation strategy to use for the model response.
 *
 * @remarks
 * - auto: If input exceeds context window, truncate by dropping items from beginning
 * - disabled: Request fails with 400 error if input exceeds context window (default)
 */
export type Truncation = ClosedEnum<typeof Truncation>;

/**
 * Up to 4 sequences where the API will stop generating further tokens
 */
export type ResponseRequestStop = string | Array<string>;

export type ResponseRequest = {
  /**
   * Model name
   */
  model: string;
  /**
   * Input content, required parameter. Can be:
   *
   * @remarks
   * - String: Single text input
   * - Message array: Structured conversation history
   *
   * **Important limitations:**
   * - Messages only support basic fields (role, content, name)
   * - Does not support tool_calls, tool_call_id and other tool-related fields
   * - content field is required and cannot be null
   * - To use tools, define them in the top-level tools parameter; model will call them on first response
   *
   * Note: Responses API has deprecated messages parameter, now uses input parameter uniformly
   */
  input: string | Array<Message>;
  /**
   * System-level instructions to guide model behavior and response style (similar to system message)
   */
  instructions?: string | undefined;
  /**
   * Controls output randomness, higher values mean more random
   */
  temperature?: number | undefined;
  /**
   * Nucleus sampling parameter, controls output diversity
   */
  topP?: number | undefined;
  /**
   * Maximum number of tokens to generate
   */
  maxOutputTokens?: number | undefined;
  /**
   * Whether to enable streaming
   */
  stream?: boolean | undefined;
  /**
   * Response modality types
   */
  modalities?: Array<ResponseRequestModalities> | undefined;
  /**
   * Available tools list (using flat format)
   */
  tools?: Array<ResponseTool> | undefined;
  /**
   * Tool selection strategy
   */
  toolChoice?: ToolChoice | ResponseRequest1 | undefined;
  /**
   * Whether to enable parallel function calling during tool use. When false, ensures exactly zero or one tool is called.
   */
  parallelToolCalls?: boolean | undefined;
  /**
   * Text output configuration
   */
  text?: Text | undefined;
  /**
   * The ID of a previous response to continue the conversation from. This allows you to chain responses together and maintain conversation state.
   *
   * @remarks
   * When using previous_response_id, the model will automatically have access to all previously produced reasoning items and conversation history.
   */
  previousResponseId?: string | undefined;
  /**
   * Whether to store the generated model response for later retrieval via API.
   *
   * @remarks
   * Defaults to true. Set to false to disable storage (required for ZDR organizations).
   */
  store?: boolean | undefined;
  /**
   * Whether to run the model response in the background asynchronously. Useful for long-running tasks.
   */
  background?: boolean | undefined;
  /**
   * Configuration for reasoning models (e.g., o1, o3, gpt-5). Controls how the model uses reasoning tokens to "think" through the problem.
   */
  reasoning?: Reasoning | undefined;
  /**
   * The truncation strategy to use for the model response.
   *
   * @remarks
   * - auto: If input exceeds context window, truncate by dropping items from beginning
   * - disabled: Request fails with 400 error if input exceeds context window (default)
   */
  truncation?: Truncation | undefined;
  /**
   * Up to 4 sequences where the API will stop generating further tokens
   */
  stop?: string | Array<string> | undefined;
  /**
   * Additional metadata for tracking and organization purposes
   */
  metadata?: { [k: string]: any } | undefined;
};

/** @internal */
export type Input$Outbound = string | Array<Message$Outbound>;

/** @internal */
export const Input$outboundSchema: z.ZodMiniType<Input$Outbound, Input> =
  smartUnion([z.string(), z.array(Message$outboundSchema)]);

export function inputToJSON(input: Input): string {
  return JSON.stringify(Input$outboundSchema.parse(input));
}

/** @internal */
export const ResponseRequestModalities$outboundSchema: z.ZodMiniEnum<
  typeof ResponseRequestModalities
> = z.enum(ResponseRequestModalities);

/** @internal */
export const ResponseRequest1$outboundSchema: z.ZodMiniEnum<
  typeof ResponseRequest1
> = z.enum(ResponseRequest1);

/** @internal */
export type ResponseRequestToolChoice$Outbound = ToolChoice$Outbound | string;

/** @internal */
export const ResponseRequestToolChoice$outboundSchema: z.ZodMiniType<
  ResponseRequestToolChoice$Outbound,
  ResponseRequestToolChoice
> = smartUnion([ToolChoice$outboundSchema, ResponseRequest1$outboundSchema]);

export function responseRequestToolChoiceToJSON(
  responseRequestToolChoice: ResponseRequestToolChoice,
): string {
  return JSON.stringify(
    ResponseRequestToolChoice$outboundSchema.parse(responseRequestToolChoice),
  );
}

/** @internal */
export const ResponseRequestType$outboundSchema: z.ZodMiniEnum<
  typeof ResponseRequestType
> = z.enum(ResponseRequestType);

/** @internal */
export type ResponseRequestFormat$Outbound = {
  type?: string | undefined;
  name?: string | undefined;
  schema?: { [k: string]: any } | undefined;
  strict?: boolean | undefined;
};

/** @internal */
export const ResponseRequestFormat$outboundSchema: z.ZodMiniType<
  ResponseRequestFormat$Outbound,
  ResponseRequestFormat
> = z.object({
  type: z.optional(ResponseRequestType$outboundSchema),
  name: z.optional(z.string()),
  schema: z.optional(z.record(z.string(), z.any())),
  strict: z.optional(z.boolean()),
});

export function responseRequestFormatToJSON(
  responseRequestFormat: ResponseRequestFormat,
): string {
  return JSON.stringify(
    ResponseRequestFormat$outboundSchema.parse(responseRequestFormat),
  );
}

/** @internal */
export const Verbosity$outboundSchema: z.ZodMiniEnum<typeof Verbosity> = z.enum(
  Verbosity,
);

/** @internal */
export type Text$Outbound = {
  format?: ResponseRequestFormat$Outbound | undefined;
  verbosity?: string | undefined;
};

/** @internal */
export const Text$outboundSchema: z.ZodMiniType<Text$Outbound, Text> = z.object(
  {
    format: z.optional(z.lazy(() => ResponseRequestFormat$outboundSchema)),
    verbosity: z.optional(Verbosity$outboundSchema),
  },
);

export function textToJSON(text: Text): string {
  return JSON.stringify(Text$outboundSchema.parse(text));
}

/** @internal */
export const Effort$outboundSchema: z.ZodMiniEnum<typeof Effort> = z.enum(
  Effort,
);

/** @internal */
export type Reasoning$Outbound = {
  effort?: string | undefined;
  summary?: string | undefined;
};

/** @internal */
export const Reasoning$outboundSchema: z.ZodMiniType<
  Reasoning$Outbound,
  Reasoning
> = z.object({
  effort: z.optional(Effort$outboundSchema),
  summary: z.optional(z.string()),
});

export function reasoningToJSON(reasoning: Reasoning): string {
  return JSON.stringify(Reasoning$outboundSchema.parse(reasoning));
}

/** @internal */
export const Truncation$outboundSchema: z.ZodMiniEnum<typeof Truncation> = z
  .enum(Truncation);

/** @internal */
export type ResponseRequestStop$Outbound = string | Array<string>;

/** @internal */
export const ResponseRequestStop$outboundSchema: z.ZodMiniType<
  ResponseRequestStop$Outbound,
  ResponseRequestStop
> = smartUnion([z.string(), z.array(z.string())]);

export function responseRequestStopToJSON(
  responseRequestStop: ResponseRequestStop,
): string {
  return JSON.stringify(
    ResponseRequestStop$outboundSchema.parse(responseRequestStop),
  );
}

/** @internal */
export type ResponseRequest$Outbound = {
  model: string;
  input: string | Array<Message$Outbound>;
  instructions?: string | undefined;
  temperature?: number | undefined;
  top_p?: number | undefined;
  max_output_tokens?: number | undefined;
  stream: boolean;
  modalities?: Array<string> | undefined;
  tools?: Array<ResponseTool$Outbound> | undefined;
  tool_choice?: ToolChoice$Outbound | string | undefined;
  parallel_tool_calls: boolean;
  text?: Text$Outbound | undefined;
  previous_response_id?: string | undefined;
  store: boolean;
  background: boolean;
  reasoning?: Reasoning$Outbound | undefined;
  truncation: string;
  stop?: string | Array<string> | undefined;
  metadata?: { [k: string]: any } | undefined;
};

/** @internal */
export const ResponseRequest$outboundSchema: z.ZodMiniType<
  ResponseRequest$Outbound,
  ResponseRequest
> = z.pipe(
  z.object({
    model: z.string(),
    input: smartUnion([z.string(), z.array(Message$outboundSchema)]),
    instructions: z.optional(z.string()),
    temperature: z.optional(z.number()),
    topP: z.optional(z.number()),
    maxOutputTokens: z.optional(z.int()),
    stream: z._default(z.boolean(), false),
    modalities: z.optional(z.array(ResponseRequestModalities$outboundSchema)),
    tools: z.optional(z.array(ResponseTool$outboundSchema)),
    toolChoice: z.optional(
      smartUnion([ToolChoice$outboundSchema, ResponseRequest1$outboundSchema]),
    ),
    parallelToolCalls: z._default(z.boolean(), true),
    text: z.optional(z.lazy(() => Text$outboundSchema)),
    previousResponseId: z.optional(z.string()),
    store: z._default(z.boolean(), true),
    background: z._default(z.boolean(), false),
    reasoning: z.optional(z.lazy(() => Reasoning$outboundSchema)),
    truncation: z._default(Truncation$outboundSchema, "disabled"),
    stop: z.optional(smartUnion([z.string(), z.array(z.string())])),
    metadata: z.optional(z.record(z.string(), z.any())),
  }),
  z.transform((v) => {
    return remap$(v, {
      topP: "top_p",
      maxOutputTokens: "max_output_tokens",
      toolChoice: "tool_choice",
      parallelToolCalls: "parallel_tool_calls",
      previousResponseId: "previous_response_id",
    });
  }),
);

export function responseRequestToJSON(
  responseRequest: ResponseRequest,
): string {
  return JSON.stringify(ResponseRequest$outboundSchema.parse(responseRequest));
}
