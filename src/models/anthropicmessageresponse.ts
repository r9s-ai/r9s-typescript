/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v4-mini";
import { SDKValidationError } from "../errors/sdkvalidationerror.js";
import { remap as remap$ } from "../lib/primitives.js";
import { safeParse } from "../lib/schemas.js";
import * as openEnums from "../types/enums.js";
import { OpenEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import * as types from "../types/primitives.js";
import {
  AnthropicContent,
  AnthropicContent$inboundSchema,
} from "./anthropiccontent.js";

export const StopReason = {
  EndTurn: "end_turn",
  MaxTokens: "max_tokens",
  StopSequence: "stop_sequence",
  ToolUse: "tool_use",
  PauseTurn: "pause_turn",
  Refusal: "refusal",
} as const;
export type StopReason = OpenEnum<typeof StopReason>;

export type AnthropicMessageResponseUsage = {
  /**
   * Number of input tokens used
   */
  inputTokens: number;
  /**
   * Number of input tokens used to create cache entries (only present if prompt caching is used)
   */
  cacheCreationInputTokens?: number | undefined;
  /**
   * Number of input tokens read from cache (only present if prompt caching is used)
   */
  cacheReadInputTokens?: number | undefined;
  /**
   * Number of output tokens generated
   */
  outputTokens: number;
};

export type AnthropicMessageResponse = {
  id: string;
  type: "message";
  role: "assistant";
  content: Array<AnthropicContent>;
  model: string;
  /**
   * Reason why the model stopped:
   *
   * @remarks
   * - end_turn: Natural completion
   * - max_tokens: Hit max_tokens limit
   * - stop_sequence: Hit a stop sequence
   * - tool_use: Model wants to use a tool
   * - pause_turn: Long-running task paused (extended thinking)
   * - refusal: Content policy violation
   */
  stopReason: StopReason | null;
  stopSequence?: string | null | undefined;
  usage: AnthropicMessageResponseUsage;
};

/** @internal */
export const StopReason$inboundSchema: z.ZodMiniType<StopReason, unknown> =
  openEnums.inboundSchema(StopReason);

/** @internal */
export const AnthropicMessageResponseUsage$inboundSchema: z.ZodMiniType<
  AnthropicMessageResponseUsage,
  unknown
> = z.pipe(
  z.object({
    input_tokens: types.number(),
    cache_creation_input_tokens: types.optional(types.number()),
    cache_read_input_tokens: types.optional(types.number()),
    output_tokens: types.number(),
  }),
  z.transform((v) => {
    return remap$(v, {
      "input_tokens": "inputTokens",
      "cache_creation_input_tokens": "cacheCreationInputTokens",
      "cache_read_input_tokens": "cacheReadInputTokens",
      "output_tokens": "outputTokens",
    });
  }),
);

export function anthropicMessageResponseUsageFromJSON(
  jsonString: string,
): SafeParseResult<AnthropicMessageResponseUsage, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AnthropicMessageResponseUsage$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AnthropicMessageResponseUsage' from JSON`,
  );
}

/** @internal */
export const AnthropicMessageResponse$inboundSchema: z.ZodMiniType<
  AnthropicMessageResponse,
  unknown
> = z.pipe(
  z.object({
    id: types.string(),
    type: types.literal("message"),
    role: types.literal("assistant"),
    content: z.array(AnthropicContent$inboundSchema),
    model: types.string(),
    stop_reason: types.nullable(StopReason$inboundSchema),
    stop_sequence: z.optional(z.nullable(types.string())),
    usage: z.lazy(() => AnthropicMessageResponseUsage$inboundSchema),
  }),
  z.transform((v) => {
    return remap$(v, {
      "stop_reason": "stopReason",
      "stop_sequence": "stopSequence",
    });
  }),
);

export function anthropicMessageResponseFromJSON(
  jsonString: string,
): SafeParseResult<AnthropicMessageResponse, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AnthropicMessageResponse$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AnthropicMessageResponse' from JSON`,
  );
}
